# PREDICCIÓN DE MANIPULACIÓN DE LAS GANANCIAS UTILIZANDO MACHINE LEARNIG
**Comprensión del negocio**
## Determinar objetivos del negocio
### Contexto
El fraude por manipulación de información contable implica que los directivos intencionalmente o por desconocimiento, permiten que se manipule la información contable, reflejando resultados que se desean, en vez de mostrar las transacciones de forma neutral y razonable. Lo cual se realiza por medio del aprovechamiento de la ambigüedad o inexistencia en las normas, técnicas y procedimientos contables, la diversidad de opciones para reflejar contablemente, y la opción de aplicar supuestos sobre los acontecimientos futuros, para exponer los hechos económicos y financieros de manera que satisfaga las necesidades de los directivos en su objetivo de ofrecer información distorsionada a los usuarios de la contabilidad (2016, Santos). 

Por ejemplo, con el gasto de depreciación de los activos fijos tangibles el resultado puede manipularse desde que se estima la vida útil del activo, en la determinación del grupo de activos fijos donde clasificará para obtener mayores o menores montos de depreciación, o cambiando el método de depreciación de un periodo a otro (1993, Naser). Otra modalidad de tergiversar el gasto comienza al elegirla cuenta, elemento, subelemento y partida donde se registra, para que su expresión contable reconozca una ejecución o inejecución con relación al presupuesto, de manera que se distorsione la expresión del gasto según su naturaleza e incida en los niveles de utilidad reflejados en el estado de rendimiento financiero.

Para el objetivo anterior también se aprovechan la subjetividad en la creación de las provisiones, el cargar gastos a las reservas patrimoniales que deberían registrarse en cuentas de gasto operacionales, y contabilizar en las partidas genéricas "otros" gastos que por su naturaleza deberían registrarse en alguna partida específica. En el caso de los inventarios, la manipulación del gasto comienza desde el momento en que se clasifica. Por ejemplo, si se considera un útil y es reconocido como gasto al concluir su vida útil no tiene el mismo efecto que si se cataloga como otro tipo de inventario (2016, Santos).

Igualmente, pueden tomarse decisiones intencionales con los gastos de investigación y desarrollo en cuanto a cuándo se reconocen o si se difieren y en qué cuantía se hace, lo que afecta el resultado; asimismo ocurre con los gastos de reparación y conservación, y los de publicidad. Incluso en el proceso de consolidación de los estados financieros se manipula la información y se decide qué ingresos y gastos, qué cuentas por cobrar o pagar, y qué aspectos patrimoniales relacionados con el grupo económico no se eliminan, para reflejar resultados económicos y financieros ficticios.
#### *Detección de Fraude*
Manuel Rejón en 2016 nos expone una lista de posibles acciones que pueden tomar la empresas para detectar manipulación de información financiera.

- **Comparación con los datos sectoriales:** Si se comparan las cifras de la empresa con las magnitudes sectoriales –hoy en día fácilmente obtenibles de fuentes como, por ejemplo, Banco de España, Registradores, Axesor, Informa, etc.- en relación con las principales magnitudes del balance y la cuenta de resultados, se pueden obtener importantes indicios de anomalías en la contabilidad de una empresa en relación con las tendencias
- **Cumplimiento en la elaboración de las cuentas anuales:** Los estados financieros deben ser elaborados con la información mínima exigida en el PGC y PGC PYMES (o el marco de información financiera que aplique) y además ofrecer más información sobre hechos, transacciones o saldos de especial relevancia. De lo contrario, la falta de información por ejemplo en la memoria, se podría considerar un importante indicio de fraude. 
- **Tendencias en las cuentas de resultados**. Con carácter general, las partidas del margen bruto deben evolucionar de forma similar, es decir, si la cifra de negocios aumenta un 20%, la partida de aprovisionamientos debe rondar dicho incremento. La cifra de gastos de personal también evoluciona de forma parecida a las dos anteriores, aunque con un poco más de retardo. 
- **Tener controladas las partidas de estimaciones que son las reinas de la manipulación: amortizaciones, deterioros y provisiones:** El inmovilizado debe por lo general tener un ratio [amortización / inmovilizado bruto] con pocas alteraciones, salvo modificaciones importantes del cálculo de amortización que obedezcan a altas o bajas de inmovilizado. Finalmente, en relación con las provisiones, deberá ser analizada con cautela las dotaciones de estas, y con la misma desconfianza las reversiones de estas. Recurrir a fuentes de información externas (prensa, etc.) puede ayudarnos a tomar una mejor decisión sobre la bondad de la contabilización de las provisiones.
- **Clasificación en el corto/largo plazo:** Prestar especial atención a partidas del corto plazo que presentan saldos que incrementan año tras año (por ejemplo, otros activos financieros, que puede contener saldos con entidades vinculadas), y que podrían representar partidas que no parecen devolverse nunca, por lo que quizá su destino estaría en el largo plazo. 
- **Partidas susceptibles de diferente clasificación:** Hay partidas que, por su naturaleza, pese a ser inmovilizado realmente, la empresa aprovecha para clasificarlas como activo corriente, y así aumentar el fondo de maniobra.
- **Activos financieros:** mayor problema suele darse cuando los activos mantenidos para negociar se eternizan en el balance, cuando su naturaleza es de recuperación inmediata en el corto plazo. Es decir, tiene vocación de largo plazo, pero se mantienen en el corto plazo, quizá para mantener un mejor fondo de maniobra. Suele ser un error/irregularidad recurrente. 
- **Activos por impuestos diferidos:** Si el usuario observa que la empresa obtiene pérdidas continuas y, aun así, se registran activos por impuestos diferidos (entre ellos, créditos por pérdidas a compensar), es posible que dichos créditos futuros sean no sean activables y, por tanto, no recuperables. 
- **Razonabilidad:** Las partidas que existen en el balance deben plasmar una razonabilidad con la cuenta de pérdidas y ganancias. Por ejemplo, si hay activos financieros lo normal es que en la cuenta de pérdidas y ganancias se reflejen ingresos financieros a modo de rendimiento (dividendos, plusvalías); de forma paralela, si hay deudas con entidades de créditos, lo razonable es que se generen gastos financieros por un importe acorde a dichas deudas.
- **Pasivos financieros.** Aquí hay varias cuestiones importantes a considerar. La primera es que debe haber una adecuada reclasificación del largo al corto plazo en deudas con entidades de crédito y arrendamientos financieros, lo que lógicamente minora el fondo de maniobra. En segundo lugar, se debe prestar atención a las pólizas de crédito cuya renovación contractual es anual, pero puede existir la tentación de reclasificarlas al largo plazo dado su carácter de “permanencia”, lo cual esconde la oscura finalidad de obtener un fondo de maniobra positivo o menos negativo. 
#### *The Detection of Earnings Manipulation (Messod D. Beneish)*
En 1999 Messod Benish profesor asociado de la universidad de indiana presenta un estudio en el cual se perfila una muestra de manipuladores, identifica sus características y propone un modelo para su detección, para lo cual se basa en la información de 74 empresas que manipularon sus ganancias entre 1982 – 1992y fueron descubiertas versus empresas del mismo periodo, y 2.332 empresas sin manipulación entre las cuales se corre el sesgo de que existan empresas con manipulación no detectadas. 

Para lo anterior propone el uso de un modelo de la forma:

M=X+ε

Donde M es una variable dicotómica codificada 1 para manipuladores y 0 de lo contrario, X es la matriz de variables explicativas, y ε es un vector de residuos. El cual va a usar las siguientes variables como predictoras del modelo, por su respectiva relación con la manipulación de ganancias.

1. ` `**Índice de días de ventas en cuentas por cobrar (DSRI)**

Es la relación de los días en la rotación en cuentas por cobrar respecto al año anterior. Un gran aumento en los días de ventas en cuentas por cobrar podría ser el resultado de un cambio en la política de crédito para estimular las ventas frente a una mayor competencia, pero aumentos desproporcionados en las cuentas por cobraren relación con las ventas también puede sugerir una inflación de ingresos.

1. **Índice de margen bruto (GMI):**

Es la relación entre los activos no corrientes (diferentes a planta, propiedad y equipos) y los activos totales de un año versus el año anterior. Lev y Thiagarajan (1993) sugieren que el deterioro del margen bruto es una señal negativa sobre las perspectivas de las empresas. Si las empresas con perspectivas más pobres tienen más probabilidades de involucrarse en la manipulación de ganancia.

1. **Índice de calidad de activos (AQI):**

Es la relación entre los activos no corrientes (diferentes a planta, propiedad y equipos) y los activos totales de un año versus el año anterior. Si AQI es mayor que 1, indica que la empresa potencialmente ha aumentado su participación en el aplazamiento de costos. Así espero una relación positiva entre AQI y la probabilidad de manipulación de ganancias.

1. **Índice de crecimiento de ventas (SGI):**

Es la relación de ventas de un año con respecto al año anterior. El crecimiento no implica manipulación, pero las empresas en crecimiento son vistas por los profesionales como más propensas a comprometer fraude de estados financieros porque su posición financiera y necesidades de capital ejercen presión sobre gerentes para lograr objetivos de ganancias. Por lo tanto, se espera una relación positiva entre SGI y la probabilidad de ganancias manipulación.

1. **Índice de depreciación (DEPI):**

Es la relación de la tasa de depreciación de un año con respecto al año anterior. Un DEPI mayor que 1 indica que la tasa a la que se deprecian los activos tiende a ralentizarse, lo que aumenta la posibilidad de que la empresa haya revisado al alza las estimaciones de activos o adoptó un nuevo método que aumenta los ingresos. 

1. **Índice de gastos generales y administrativos de ventas (SGAI):**

Es la relación de gastos de venta, generales y administrativos de un año con respecto al año anterior.

1. **Índice de apalancamiento (LVGI):**

Es la relación entre la deuda y los activos totales de un año con respecto al año anterior. La variable está incluida para capturar incentivos de convenios de deuda para la manipulación de ganancias. Suponiendo que apalancamiento sigue una caminata aleatoria, LVGI mide implícitamente el error de pronóstico de apalancamiento.

1. **ACCR (Total Ingresos – Total de Activos):** 

Se calcula como el cambio en las cuentas de capital de trabajo que no sea la depreciación sin efectivo.

Utilizado para evaluar en qué medida los gerentes toman decisiones contables discrecionales para alterar las ganancias (Healy (1985), Jones (1991). Utilizo las acumulaciones totales para los activos totales para ponderar la medida en que el efectivo subyace a las ganancias reportadas.

Finalmente, la ejecución del modelo de Benish utilizando estimaciones probabilísticas logra predecir correctamente entre un 37.5% a 56% de los manipuladores y clasifica erróneamente a 9.1% de las empresas no manipuladas como manipuladoras
### Objetivos de negocio
- Detectar, basado en la información financiera de los clientes posibles casos de manipulación de ganancias.
### Criterios del éxito del caso
- Obtener una precisión en la clasificación de los clientes superior a la entregada por el M-Score (Beneish) aplicada sobre los mismos datos.
## Determinar objetivos de la minería de datos
- Diseñar, construir e implementar un modelo de clasificación de clientes basado en la información financiera publicada, que permita la predicción en Manipuladores y No Manipuladores.
### Criterios de éxito de la minería
• 	Lograr una predicción que genere el mejor nivel de predicción en los datos de prueba, evaluado en base a la exactitud y el ROC.
# Comprensión de datos
## Descripción de los datos
La información presentada para estudio corresponde a 1239 observaciones cada una correspondiente a una empresa distinta con el detalle de 8 ratios financieros utilizados para la formulación del M-Score. Que son:

1. DSRI (Índice de ventas en cuentas por cobrar)
1. SGI (Índice de crecimiento de ventas)
1. DEPI (Depreciación)
1. SGAI (Ventas, gastos generales y administrativos)
1. ACCR (Total Ingresos – Total de Activos)
1. LEVI (Deuda – Patrimonio)

Adicionalmente el conjunto de datos contiene dos columnas con la clasificación real de la compañía como manipuladora o no-manipuladora. De las 1.239 observaciones 1.200 son clasificadas en la clase No-Manipulador y 39 en la Manipuladora.

También se cuenta con una columna de ID que contiene representa un identificar única para cada empresa.

![](011.png)

*Figura 1. Exploración Inicial de los datos*

![](012.png)

*Figura 2. Distribución de la variable C-manipulator*
## Estructura de los datos
El conjunto de datos está conformado por 9 variables numéricas correspondientes a los ratios financieras y la columna de ID, y dos columnas de tipo factor de la variable Manipulador.

|**Variable**|**Tipo**|
| - | - |
|**Company ID**|int|
|**DSRI**|num|
|**GMI**|num|
|**AQI**|num|
|**SGI**|num|
|**DEPI**|num|
|**SGAI**|num|
|**ACCR**|num|
|**LEVI**|num|
|**Manipulater**|Factor|
|**C.MANIPULATOR**|Factor|


### Granularidad
La información no presenta niveles de granularidad o jerarquización en sus variables.

### Temporalidad
La información no presenta variables asociadas a temporalidad, pero por información publicada en el caso se sabe que fue recolectada entre los años de 2005 a 2015 de los reportes SEBI (Securities and Exchange Board of India) y la base de datos Lexis Nexis (Empresa especializada en asesoría legal a empresas y gestión de riesgos).
### Geografía
El estudio está desarrollado para empresas de la India, pero no se proporciona detalle de ubicación de dichas empresas.
## Exploración de datos
### Variables Numéricas
La variable correspondiente al ID será removida del conjunto de datos ya no aportada información descriptiva de las empresas.

A continuación, iniciamos la exploración de las variables correspondientes a los ratios financieros con la generación de sus descriptivos estadísticos. 

![](013.png)

Las variables muestran en sus estadísticos características de una alta variabilidad como se ve en los coeficientes de variación bastantes altos, sin embargo, al observar los valores de la curtosis bastante altos también podemos pensar que la variabilidad está siendo afectada por valores extremos muy lejanos, que al analizar los valores de la mediana (en su mayoría cercanos a uno) frente a los valores máximos (en su mayoría 30 o cuarenta veces mayor) esta interpretación se ve confirmada. Observamos que las variables presentan altas asimetrías positivas a excepción de ACCR que muestra asimetría negativa.

A continuación, analizaremos los gráficos de dispersión de las variables para obtener más información de la distribución de estas variables.

**DSRI**

![](014.png)![](015.png)

*Figura 3. Distribución de la variable DSRI* 


**GMI**

![](016.png)![](017.png)

*Figura 4. Distribución de la variable GMI*

**AQI**

![](018.png)![](019.png)

*Figura 5. Distribución de la variable AQI*

**SGI**

![](020.png)![](021.png)

*Figura 6. Distribución de la variable SGI*

**DEPI**

![](022.png)![](023.png)

*Figura 7. Distribución de la variable DEPI*

**SGAI**

![](024.png)![](025.png)

*Figura 8. Distribución de la variable SGAI*



<a name="_hlk19540604"></a>**ACCR**

![](026.png)![](027.png)

*Figura 10. Distribución de la variable ACCR*

**LEVI**

![](028.png)![](029.png)

*Figura 11. Distribución de la variable LEVI.* 

En general las variables muestran una importante presencia de datos extremos, pero dado que nuestro problema es sobre la identificación de casos anómalos que nos lleven a la clasificación de una posible manipulación de ganancias, consideramos no adecuado realizar en principio un tratamiento de estos atípicos ya que perderíamos información relevante en el caso de estudio, en particular dado que las variables en su mayoría muestran la relación de los índices financieros frente al año anterior, son los valores extremos altos los más interesantes.

Más adelante revisaremos que transformaciones nos pueden ayudar para tratar de normalizar las variables. Que para todas las variables a excepción de ACCR nos muestra una asimetría positiva por lo que buscaremos la compresión de los datos altos.

Sin embargo, en el análisis de la variable **ACCR** podemos observar una distribución con tendencia normal que la medida si no se tiene en cuenta el dato extremo inferior de -3.1435, por lo que podemos pensar en su supresión en lugar de una transformación de la variable. Caso similar para la variable **GMI**.

### Análisis de correlación
Dado que una correlación alta entre las variables podría generar en el modelo una incorrecta ponderación en cuanto a la importancia de las variables correlacionadas vamos a analizar si existe entre las variables numéricas altos grados de correlación.

![](030.png)

En general las variables no muestras correlaciones importantes, la más relevante se entre DSRI y SGAI, pero es de 0.47 un valor bajo para efectos del modelado. 
### Variable de respuesta
Para tratar de identificar las variables con mayor influencia, analizaremos el comportamiento de estas con respecto a la variable de respuesta **Manipulador**. Según se puede observar las variables presentan distribuciones y densidades similares para los dos casos, con mucha cercanía en sus medianas, pero los valores extremos en cada caso son los que aportan mayor diferenciación entre una clase y otro.

A continuación, presentamos los gráficos de violín de cada variable para las dos clases donde queda evidenciado el comportamiento anterior.

**DSRI**

![](031.png)

*Figura 13. Relación de la variable DSRI respecto a la variable de respuesta*

La variable DSRI muestra que aquellas empresas Manipuladoras tienen una mayor presencia de valores extremos altos, lo cual tiene sentido ya que un alto valore de esta variable sugiere un reconocimiento acelerado de ingresos para inflar las ganancias.

**GMI**

![](032.png)

*Figura 14. Relación de la variable GMI respecto a la variable de respuesta*

La variable GMI también presenta mayor presencia de valores extremos altos para la clase **Manipulador,** con la diferencia que los valores extremos bajos parecen ser propios de la clase **No Manipulador**.

**AQI**

![](033.png)

*Figura 15. Relación de la variable AQI respecto a la variable de respuesta*

Al igual que la variable anterior vemos valores extremos altos para la clase **Manipulador** y los valores extremos bajos parecen ser propios de la clase **No Manipulador**.

**SGI**

![](034.png)

*Figura 16. Relación de la variable SGI respecto a la variable de respuesta*

SGI presenta distribuciones muy parecidas con mayor densidad de valores extremos para la clase **Manipulador.**

**DEPI**

![](035.png)

*Figura 17. Relación de la variable DEPI respecto a la variable de respuesta*

La variable DEPI a diferencia de las anteriores no muestra preponderancia de valores extremos altos para la clase **Manipulador,** por el contrario, se observa una ligera mayor densidad para valores por debajo de la mediana. Lo anterior tiene sentido si consideramos que un nivel de depreciación decreciente en relación con los activos fijos netos aumenta la posibilidad de que una empresa haya revisado al alza la vida útil estimada de los activos, o haya adoptado un nuevo método que aumente los ingresos.

**SGAI**

![](036.png)

*Figura 18. Relación de la variable SGAI respecto a la variable de respuesta*

SGI presenta mayor presencia de valores extremos para la clase **Manipulador.**

**ACCR**

![](037.png)

*Figura 19. Relación de la variable ACCR respecto a la variable de respuesta*

Vemos que para la variable ACCR en la clase **Manipulador,** tiene una mayor densidad de observaciones en sus intervalos de confianza.

**LEVI**

![](038.png)

*Figura 20. Relación de la variable LEVI respecto a la variable de respuesta*

LEVI presenta mayor presencia de valores extremos para la clase **Manipulador.**


## Verificación de la calidad de los datos
El proceso de revisión de los datos que participarían en la construcción del modelo arrojó los siguientes resultados:

**Datos Faltantes:** El conjunto de datos no presenta datos faltantes en ninguna de sus variables.

`	`![](039.png)

**Rango de variables**: Dado que las variables son ratios o razones entre dos cantidades en principio similares se esperan valores de magnitud baja como en realidad se muestran en los datos.

**Categorías de clase**: La variable de respuesta presenta dos categorías como nos indica el problema y cada empresa pertenece a una y solo una clase. Adicionalmente, la correspondencia entre las dos variables que indican la clase es correcta.
# Preparación de los datos
## Selección de los datos
Del conjunto de variables originales de la base de entrenamiento no serán tenidas para la construcción del modelo:

- **ID:** Variable de identificación que no aporta información adicional al modelo.
- **Columna de Clase:** El conjunto de datos presenta dos variables con la clase de la empresa para efecto del modelo tomaremos la columna con valores binarios de 1 o 0 **C-MANIPULATOR**.
## Limpieza de los datos
**Tratamiento de Atípicos**: Con la información obtenida en la exploración de datos y análisis de contextos, no se considera prudente un tratamiento de datos extremos ya que debido a la naturaleza del problema podemos tener una pérdida de información relevante, sin embargo, para las variables **ACCR Y GMI** vemos como un valor extremo bajo comprime de forma extrema su distribución, por lo cual este dato extremo será sometido al tratamiento de supresión.

A continuación, se detalla la mejoría en los estadísticos más relevantes luego del tratamiento de atípicos para las variables mencionadas. 

<table><tr><th colspan="1" rowspan="2" valign="top"><b>VARIABLE</b></th><th colspan="2" valign="top"><b>ASIMETRIA</b></th><th colspan="2" valign="top"><b>CURTOSIS</b></th></tr>
<tr><td colspan="1" valign="top"><b>Antes</b></td><td colspan="1" valign="top"><b>Después</b></td><td colspan="1" valign="top"><b>Antes</b></td><td colspan="1" valign="top"><b>Después</b></td></tr>
<tr><td colspan="1" valign="top"><b>ACCR</b></td><td colspan="1" valign="top">-8.54</td><td colspan="1" valign="top">-0.38</td><td colspan="1" valign="top">188\.15</td><td colspan="1" valign="top">18\.1</td></tr>
<tr><td colspan="1" valign="top"><b>GMI</b></td><td colspan="1" valign="top">16\.54</td><td colspan="1" valign="top">-4.98</td><td colspan="1" valign="top">575\.05</td><td colspan="1" valign="top">96\.41</td></tr>
</table>

*Tabla 3. Tratamiento de datos atípicos*

Luego de este tratamiento el conjunto de datos queda con 1236 observaciones.

![](040.png)

*Figura 21. Base de datos segmentada* 

**Ejemplo de transformación gráfica de densidad ACCR.**

![](041.png)

![](042.png)

*Figura 22. Cambio en Distribución de la variable ACCR*
## Estructuración de los datos
Como pudimos observar en la exploración de datos las variables presentan importantes casos de asimetría mayormente positivas y casos de valores extremos importantes, que pueden afectar el modelo.

Las variables a excepción ACCR presentan asimetría positiva lo que nos sugiere una transformación logarítmica para buscar la compresión de los valores altos. Pero dada la naturaleza de las variables como razones de crecimiento o decrecimiento de indicadores financieros, el conjunto de datos en todas las variables presenta valores menores que cero, los cuales al aplicarse una función de logaritmo generarían valores de infinito o error. Para buscar una función de transformación para estas variables podemos pensar en un desplazamiento del valor mínimo y de esta forma el valor mínimo sería el nuevo valor cero y el resto de las observaciones se ubicarían hacia su derecha. A continuación, veamos el detalle de la fórmula:

log(x- minx+1)

Las variables que muestran altos valores de asimetría y curtosis que serán sometidas a la transformación logarítmica presentada son **DSRI, SGI, DEPI, SGAI y LEVI**, las variables **ACCR, GMI y AQI** presentan

` `valores tolerables de estos estadísticos luego del tratamiento de atípicos y pueden ser incluidas al modelo directamente.** 

Valores de estadísticos finales luego de limpieza y transformaciones.

![](043.png)

*Tabla 4.* Valores de estadísticos finales luego de limpieza y transformaciones


# Modelado
## Generación de un plan de prueba
Se propone implementar un modelo SVM de clasificación. Dada la distribución de los datos con relación a la variable de respuesta se desarrollará inicialmente dos modelos SVM lineales sobre dos conjuntos de datos, uno con la distribución original (1.198 no manipuladores y 38 manipuladores) y otro con una muestra con un undersammpling de 220 (con los 38 manipuladores). Estos modelos servirán de base para la construcción del modelo final y ayudarán a medir el efecto de la distribución de la variable de respuesta en los datos.

Una vez determinado según validación la mejor distribución se iniciará la construcción de 5 modelos correspondientes a los kernels lineal, radial y polinomial de grados 2 a 5. Cada modelo será sintonizado en sus parámetros buscado obtener el mejor modelo correspondiente a cada kernel evaluando su precisión y área ROC en los datos de entrenamiento, validación y pruebas. Cada uno sobre dos distribuciones 1236 o 220 observaciones.

EL conjunto de datos tendrá una primera partición de 70/30 para generar los conjuntos de entrenamiento y pruebas. Los datos de pruebas se conservan originales para la evaluación. 

El conjunto de entrenamiento será nuevamente dividido en dos conjuntos de 75/25 para generar conjunto de entrenamiento y validación, esto a fin de tener mayores criterios de evaluación de los modelos resultantes.



## Construcción del modelo
La estructura final del conjunto de datos utilizado para la construcción del clasificador es:

![](044.png)

*Tabla 5. Estructura de los datos usada en el modelo clasificador*
### Modelos Base
Dado que el propósito de esta prueba es generar un modelo base no se realizarán mayores interacciones para el parámetro costo, se tomará el entregado como mejor luego del proceso de validación cruzada. Más adelante los modelos serán adecuadamente sintonizados en sus parámetros.

Se ejecutan los modelos con una configuración de lista en sus parámetros y con validación cruzada se determina los mejores valores para estos.

**Distribución original (1.200 datos)**

Manipulador         3.074%

No Manipulador   96.92%

**Distribución original (220 datos)**

Manipulador         14.72%

No Manipulador   85.27%

#### *Modelos Base Distribución original de 1.200 datos*
#### *Modelo Lineal Base*
*Parámetros encontrados: Costo = 5 Vectores de Soporte = 41*

|Conjunto de Datos |Precisión|Error|Área ROC|
| :-: | :-: | :-: | :-: |
|Entrenamiento|98\.15 %|1\.85%|0\.1470|
|Validación|97\.24%|2\.76%|0\.1470|
|Pruebas|97\.57%|2\.42%|0\.3628|

##### Modelo Radial Base
*Parámetros encontrados: Costo = 1000 Vectores de Soporte = 53 Gamma =0.01* 

|Conjunto de Datos|Precisión|Error|Área ROC|
| :-: | :-: | :-: | :-: |
|Entrenamiento|98\.52%|2\.96%|0\.9695|
|Validación|75\.56%|24\.44%|0\.7628|
|Pruebas|89\.74%|10\.25%|0\.8973|
####
##### Modelo Polinomial Base
*Parámetros encontrados: Costo = 100 Vectores de Soporte = 26 Gamma =0.125 Grado 3*

|Conjunto de Datos|Precisión|Error|Área ROC|
| :-: | :-: | :-: | :-: |
|Entrenamiento|99\.07%|0\.92%|0\.0128|
|Validación|97\.24%|2\.76%|0\.1782|
|Pruebas|96\.5%|3\.50%|0\.6782|

#### *Modelos Base Distribución 220 datos*
#### *Modelo Lineal Base*
*Parámetros encontrados: Costo = 50 Vectores de Soporte = 30*

|Conjunto de Datos|Precisión|Error|Área ROC|
| :-: | :-: | :-: | :-: |
|Entrenamiento|97\.04%|8\.88%|0\.9515|
|Validación|73\.33%|26\.66%|0\.6428|
|Pruebas|91\.03%|8\.97%|0\.6428|

##### Modelo Radial Base
*Parámetros encontrados: Costo = 50 Vectores de Soporte = 37 Gamma =0.01* 

|Conjunto de Datos|Precisión|Error|Área ROC|
| :-: | :-: | :-: | :-: |
|Entrenamiento|94\.07%|5\.92%|0\.9590|
|Validación|84\.44%|15\.55%|0\.8314|
|Pruebas|89\.74%|10\.25%|0\.9315|
####
##### Modelo Polinomial Base
*Parámetros encontrados: Costo = 100 Vectores de Soporte = 26 Gamma =0.125 Grado 3*

|Conjunto de Datos|Precisión|Error|Área ROC|
| :-: | :-: | :-: | :-: |
|Entrenamiento|98\.52%|1\.48%|0\.9803|
|Validación|73\.33%|26\.66%|0\.9803|
|Pruebas|91\.03%|8\.97%|0\.7042|

Los modelos ejecutados muestran en general buenos valores de precisión, pero no así sus valores de curva ROC. Para el conjunto de datos original de 1.200 observaciones solo el modelo Radial da un valor aceptable en pruebas de 0.8973 sin embargo este valor no es el esperado en el proyecto donde se busca un valor ROC superior al 0.95. Para el conjunto de datos observamos 220 observaciones podemos notar una mejoría sustancial en los valores de ROC, obtenido en pruebas para el modelo Radial 0.9315.

La mejoría en el desempeño del modelo con undersampling nos sugiere que con un adecuado balanceo podemos obtener un modelo que aprenda suficientemente de clase Manipulador para lograr valores deseados de precisión, exhaustividad y ROC. De lo anterior se decide probar sobre el modelo Radial obtenido otras distribuciones de balaceo a fin de obtener una mejoría sobre el modelo final.

Como método de remuestro se plantea utilizar tanto Over- And Under-Sampling que realiza un muestreo disminuyendo las observaciones de la clase mayoritaria y generado observaciones de la clase minoritaria.

El modelo base obtenido se prueba con las siguientes distribuciones de balanceo.

**Distribución 1**

No Manipulador   70%

Manipulador   30%

**Distribución 2**

No Manipulador   50%

Manipulador   50%

**Distribución 3**

No Manipulador 30%

Manipulador   70%

La distribución con mejor desempeño en datos de validación y prueba con valores de curva ROC superior a 0.90 fue el número tres (No Manipulador 30% - Manipulador 70%), donde se obtienen un conjunto con clase mayoritaria Manipuladores. Con esta distribución garantizamos un modelo con conocimiento suficiente de la clase positiva y dada la importancia de identificar la gran mayoría de los Manipuladores, será con esta distribución de se construirán y sintonizarán los modelos SVM propuestos sobre dos conjuntos de datos uno de 1.200 y otro de 220.

**Distribución Balanceada Entrenamiento (1.200 datos)**

Manipulador         70.38%

No Manipulador   29.61%

**Distribución Balanceada Entrenamiento (220 datos)**

Manipulador         68.60%

No Manipulador   31.39%


### Modelo lineal 220 datos
Se genera el modelo lineal con una configuración del valor de costo de 0.005 a 1000 y con validación cruzada se determina el mejor valor para el parámetro.

*svm\_lin <- tune (svm, MANIPULATOR ~., data = datos\_modelo. train, kernel="linear", iter.max=10000000, ranges=list (cost=c (0.005, 0.009, 0.01, 0.05, 0.1, 0.5, 1, 2, 5, 10, 50, 100, 1000)))*

Este proceso nos entrega como mejor modelo el que responde a los parámetros de costo=5 y 78 vectores dentro de un conjunto de datos de entrenamiento de 180 observaciones.

***Resultados del modelo:***

|Conjunto de Datos|Precisión|Error|Área ROC|
| :-: | :-: | :-: | :-: |
|Entrenamiento|88\.08 %|11\.91 %|0\.9191|
|Validación|93\.85%|6\.15 %|0\.9611|
|Pruebas|80\.77%|19\.23%|0\.9637|

*Tabla 10. Evaluación del modelo Lineal 220 datos*

El modelo lineal de costo 5 seleccionado nos está entregando buenos resultados, sin embargo, vamos a validar la posibilidad de expandir el rango cercano a 5 y tratar de encontrar un mejor valor para el costo.

Se prueba el rango de costos = 1,3,4.5,5,5.5,10,15,20. El mejor modelo obtenido es con costo 4.5 y 79 vectores.

***Resultados del modelo:***

|Conjunto de Datos|Precisión|Error|Área ROC|
| :-: | :-: | :-: | :-: |
|Entrenamiento|88\.08 %|11\.91 %|0\.9191|
|Validación|93\.85%|6\.15 %|0\.9611|
|Pruebas|80\.77%|19\.23%|0\.9637|

*Tabla 11. Evaluación del modelo Lineal 220 datos cambiando el rango de costos*

El modelo entrega los mismos resultados que el modelo con costo 5 lo cual tiene sentido ya que los dos modelos a pesar de valores diferentes del parámetro de costo tienen el mismo número de vectores de soporte.
#### *Mejor Modelo Lineal*
Luego de la sintonización del parámetro de costo donde no se obtuvieron diferencias significativas en las predicciones para cada valor de costo se selecciona como mejor modelo el modelo con costo de 5.

Los datos del modelo lineal son:

|<a name="_hlk21477150"></a>Conjunto de Datos|Precisión|Error|Área ROC|
| :-: | :-: | :-: | :-: |
|Entrenamiento|88\.08 %|11\.91 %|0\.9191|
|Validación|93\.85%|6\.15 %|0\.9611|
|Pruebas|80\.77%|19\.23%|0\.9637|

*Tabla 12. Evaluación del mejor modelo Lineal 220 datos*

A continuación, detalle los valores de desempeño en pruebas:

<table><tr><th colspan="1" rowspan="2" valign="top"><p></p><p>Predicción</p></th><th colspan="2" valign="top">Real - Pruebas</th></tr>
<tr><td colspan="1" valign="top"><b>0</b></td><td colspan="1" valign="top"><b>1</b></td></tr>
<tr><td colspan="1" valign="top">0</td><td colspan="1" valign="top">56</td><td colspan="1" valign="top">0</td></tr>
<tr><td colspan="1" valign="top">1</td><td colspan="1" valign="top">15</td><td colspan="1" valign="top">7</td></tr>
</table>

*Tabla 13. Matriz de confusión del modelo lineal 220 datos* 

El modelo predice el 100% de los casos positivos y una especificidad del 78.87%.

![](045.png)

*Figura 23. Curva ROC del modelo Lineal 220 datos*

### Modelo lineal 1.200 datos

Se genera el modelo lineal con una configuración del valor de costo de 0.005 a 1000 y con validación cruzada se determina el mejor valor para el parámetro.

*svm\_lin <- tune (svm, MANIPULATOR ~., data = datos\_modelo. train, kernel="linear", iter.max=10000000, ranges=list (cost=c (0.005, 0.009, 0.01, 0.05, 0.1, 0.5, 1, 2, 5, 10, 50, 100, 1000)))*

Este proceso nos entrega como mejor modelo el que responde a los parámetros de costo=100 y 289 vectores dentro de un conjunto de datos de 1236 observaciones.

***Resultados del modelo:***

|Conjunto de Datos|Precisión|Error|Área ROC|
| :-: | :-: | :-: | :-: |
|Entrenamiento|91\.8 %|8\.19 %|0\.9233|
|Validación|93\.85%|6\.14 %|0\.9484|
|Pruebas|80\.59%|19\.40%|0\.9318|

*Tabla 14. Evaluación del modelo Lineal 1200 datos*

El modelo lineal de costo 100 seleccionado nos está entregando buenos resultados, sin embargo, vamos a validar la posibilidad de expandir el rango cercano a 100 y tratar de encontrar un mejor valor para el costo.

Se prueba el rango de costos = 80, 85, 90, 95, 100, 105,110,500. El mejor modelo obtenido es con costo 80 y 293 vectores.

***Resultados del modelo:***

|Conjunto de Datos|Precisión|Error|Área ROC|
| :-: | :-: | :-: | :-: |
|Entrenamiento|91\.8 %|8\.19 %|0\.9233|
|Validación|93\.85%|6\.14 %|0\.9484|
|Pruebas|80\.59%|19\.40%|0\.9318|

`	`*Tabla 15. Evaluación del modelo Lineal 1200 datos cambiando el rango de costos*

Aunque el resultado de predicción con los dos modelos el modelo de costo 80 aumenta el número de vectores de soporte.

Expandimos nuevamente los valores del costo cercanos a 80 y evaluamos.

Se prueba el rango de costos = 50,55,60,65,70,75,80. El mejor modelo obtenido es con costo 50 y 285 vectores. Se obtienen nuevamente los mismos datos de desempeño del modelo.
#### *Mejor Modelo Lineal*
Luego de la sintonización del parámetro de costo donde no se obtuvieron diferencias significativas en las predicciones para cada valor de costo se selecciona como mejor modelo el modelo con costo de 50, que también entrega menores números de soporte lo que minimiza el mayor error posible.

Los datos del modelo lineal son:

|<a name="_hlk21477201"></a>Conjunto de Datos|Precisión|Error|Área ROC|
| :-: | :-: | :-: | :-: |
|Entrenamiento|91\.8 %|8\.19 %|0\.9233|
|Validación|93\.85%|6\.14 %|0\.9484|
|Pruebas|80\.59%|19\.40%|0\.9318|

*Tabla 16. Evaluación del mejor modelo Lineal 1200 datos*

A continuación, detalle los valores de desempeño en pruebas:

**Matriz de Confusión:**

<table><tr><th colspan="1" rowspan="2" valign="top"><p></p><p>Predicción</p></th><th colspan="2" valign="top">Real - Pruebas</th></tr>
<tr><td colspan="1" valign="top"><b>0</b></td><td colspan="1" valign="top"><b>1</b></td></tr>
<tr><td colspan="1" valign="top">0</td><td colspan="1" valign="top">289</td><td colspan="1" valign="top">1</td></tr>
<tr><td colspan="1" valign="top">1</td><td colspan="1" valign="top">71</td><td colspan="1" valign="top">10</td></tr>
</table>

*Tabla 17. Matriz de confusión del modelo lineal 1200 datos* 


El modelo predice el 99.66% de los casos positivos y una especificidad del 80.27%.

![](046.png)

*Figura 24. Curva ROC del modelo Lineal 1200 datos*


### Modelo radial 220 datos
Se genera el modelo radial con una configuración del valor de costo de 0.005 a 1000, valores de gamma de 0.01 a 100 y con validación cruzada se determina el mejor valor para el parámetro.

*svm\_rad = tune (svm, MANIPULATOR ~., data = datos\_modelo. train, kernel = "radial", iter.max=10000000,*

`              		 `*ranges = list (c (0.005, 0.009, 0.01, 0.05, 0.1, 0.5, 1, 2, 5, 10, 50, 100, 1000), gamma = c (0.01, 0.1, 1, 5, 10, 100)))*

Este proceso nos entrega como mejor modelo el que responde a los parámetros de costo=1.000, gamma=0.1 y 77 vectores dentro de un conjunto de datos de 220 observaciones.

***Resultados del modelo:***

|<a name="_hlk21477227"></a>Conjunto de Datos|Precisión|Error|Área ROC|
| :-: | :-: | :-: | :-: |
|Entrenamiento|100 %|0 %|1|
|Validación|86\.67%|13\.33%|0\.8951|
|Pruebas|78\.21%|21\.79%|0\.9318|

*Tabla 18. Evaluación del modelo radial 220 datos*

Los resultados de este modelo evidencian claramente un sobreajuste en sobre, los datos de entrenamiento, que lleva a que los resultados sobre la matriz de entrenamiento sean excelentes, pero estos no se reflejen en los resultados de validación y prueba. Por lo que se probara como en el modelo anterior limitar el rango de costo de 80 a 500, y la variación de gamma de 0.01 a 5.

El mejor modelo obtenido es con costo 70, gamma de 0.1 y 33 vectores.

***Resultados del modelo:***

|Conjunto de Datos|Precisión|Error|Área ROC|
| :-: | :-: | :-: | :-: |
|Entrenamiento|99\.2 %|7\.41 %|0\.9983|
|Validación|86\.67%|13\.3 %|0\.9012|
|Pruebas|79\.49%|20\.5 %|0\.8344|

*Tabla 19. Evaluación del modelo radial 220 datos cambiando gamma*

Este modelo demuestra una mejora significativa de los resultados, donde tenemos menos de la mitad de los vectores de soporte del resultado anterior y logramos mejoras en todos los indicadores tanto en validación como en prueba, por lo que ya no se tiene un modelo sobre ajustado.

#### *Mejor Modelo radial*
Luego de la sintonización del parámetro de costo donde no se obtuvieron diferencias significativas en las predicciones para cada valor de costo se selecciona como mejor modelo el modelo con costo de 70, gamma 0.1. Después de no encontrar otro modelo que mejorara los resultados de error.

Los datos del modelo radial son:

|<a name="_hlk21477243"></a>Conjunto de Datos|Precisión|Error|Área ROC|
| :-: | :-: | :-: | :-: |
|Entrenamiento|99\.2 %|7\.41 %|0\.9983|
|Validación|86\.67%|13\.3 %|0\.9012|
|Pruebas|79\.49%|20\.5 %|0\.8344|

*Tabla 20. Evaluación del mejor modelo radial 220 datos*


A continuación, detalle los valores de desempeño en pruebas:

**Matriz de Confusión:**

<table><tr><th colspan="1" rowspan="2" valign="top"><p></p><p>Predicción</p></th><th colspan="2" valign="top">Real - Pruebas</th></tr>
<tr><td colspan="1" valign="top"><b>0</b></td><td colspan="1" valign="top"><b>1</b></td></tr>
<tr><td colspan="1" valign="top">0</td><td colspan="1" valign="top">56</td><td colspan="1" valign="top">5</td></tr>
<tr><td colspan="1" valign="top">1</td><td colspan="1" valign="top">11</td><td colspan="1" valign="top">6</td></tr>
</table>

*Tabla 21. Matriz de confusión del modelo radial 220 datos*


El modelo predice el 91.80% de los casos positivos y una especificidad del 83.58%.

![](047.png)

*Figura 25. Curva ROC del modelo radial 1200 datos*

### Modelo radial 1.200 datos
Se genera el modelo radial con una configuración del valor de costo de 0.005 a 1000, valores de gamma de 1 a 10 y con validación cruzada se determina el mejor valor para el parámetro.

*svm\_rad = tune (svm, MANIPULATOR ~., data = datos\_modelo. train, kernel = "radial", iter.max=10000000,*

`              		 `*ranges = list (c (0.005, 0.009, 0.01, 0.05, 0.1, 0.5, 1, 2, 5, 10, 50, 100, 1000), gamma = c (0.01, 0.1, 1, 5, 10, 100)))*

Este proceso nos entrega como mejor modelo el que responde a los parámetros de costo=100, gamma=0.5 y 395 vectores dentro de un conjunto de datos de 1.200 observaciones.

***Resultados del modelo:***

|<a name="_hlk21477291"></a>Conjunto de Datos|Precisión|Error|Área ROC|
| :-: | :-: | :-: | :-: |
|Entrenamiento|100 %|0 %|1|
|Validación|100 %|0 %|1|
|Pruebas|100 %|0 %|1|

*Tabla 22. Evaluación del mejor radial 1200 datos*

Aunque el modelo logra predecir el 100 % de los casos manipulados tanto en entrenamiento como en validación, y prueba, por lo que no se consideran hacer más pruebas con otros parámetros. Sin embargo, se considera que el número de vectores es bastante alto por lo que podría ser sobre ajustado.

A continuación, detalle los valores de desempeño en pruebas:


**Matriz de Confusión Entrenamiento:**

<table><tr><th colspan="1" rowspan="2" valign="top"><p></p><p>Predicción</p></th><th colspan="2" valign="top">Real - Pruebas</th></tr>
<tr><td colspan="1" valign="top"><b>0</b></td><td colspan="1" valign="top"><b>1</b></td></tr>
<tr><td colspan="1" valign="top">0</td><td colspan="1" valign="top">273</td><td colspan="1" valign="top">0</td></tr>
<tr><td colspan="1" valign="top">1</td><td colspan="1" valign="top">0</td><td colspan="1" valign="top">654</td></tr>
</table>

*Tabla 23.* Matriz de Confusión Entrenamiento *modelo radial 1200 datos*


**Matriz de Confusión prueba:**

<table><tr><th colspan="1" rowspan="2" valign="top"><p></p><p>Predicción</p></th><th colspan="2" valign="top">Real - Pruebas</th></tr>
<tr><td colspan="1" valign="top"><b>0</b></td><td colspan="1" valign="top"><b>1</b></td></tr>
<tr><td colspan="1" valign="top">0</td><td colspan="1" valign="top">93</td><td colspan="1" valign="top">0</td></tr>
<tr><td colspan="1" valign="top">1</td><td colspan="1" valign="top">0</td><td colspan="1" valign="top">216</td></tr>
</table>

*Tabla 24.* Matriz de Confusión Prueba *modelo radial 1200 datos*


**Matriz de Confusión validación:**

<table><tr><th colspan="1" rowspan="2" valign="top"><p></p><p>Predicción</p></th><th colspan="2" valign="top">Real - Pruebas</th></tr>
<tr><td colspan="1" valign="top"><b>0</b></td><td colspan="1" valign="top"><b>1</b></td></tr>
<tr><td colspan="1" valign="top">0</td><td colspan="1" valign="top">360</td><td colspan="1" valign="top">0</td></tr>
<tr><td colspan="1" valign="top">1</td><td colspan="1" valign="top">0</td><td colspan="1" valign="top">11</td></tr>
</table>

*Tabla 25.* Matriz de Confusión Validación *modelo radial 1200 datos*


### Modelo Polinomial 220
Se genera el modelo lineal con una configuración del valor de costo de 0.005 a 1000, 2 – 3 - 4 grados de libertad, escala de -100 a 100 y con validación cruzada se determina el mejor valor para el parámetro.

`  `*svm\_pol = tune (svm, MANIPULATOR ~., data = datos\_modelo. train, kernel = "polynomial", iter.max=10000000,*

*ranges = list (cost=c (0.005, 0.009, 0.01, 0.05, 0.1, 0.5, 1, 2, 5, 10, 50, 100, 1000), degree = c (2, 3, 4), scale=c (-100, -10, -1, 1, 10, 100)))*

Este proceso nos entrega como mejor modelo el que responde a los parámetros de costo=1000, 2 grado, escala -100 y 65 vectores dentro de un conjunto de datos de 220 observaciones no manipuladas.

***Resultados del modelo:***

|Conjunto de Datos|Precisión|Error|Área ROC|
| :-: | :-: | :-: | :-: |
|Entrenamiento|96\.37 %|3\.62 %|0\.9859|
|Validación|84\.21%|10\.76 %|0\.8409|
|Pruebas|83\.33%|16\.67%|0\.8683|

*Tabla 26. Evaluación del modelo Polinomial 220 datos*

El modelo polinomial, parece generar unos muy buenos resultados que son mejores al modelo lineal y radial en una muestra de con menos casos de empresas sin manipulación financiera, también disminuye el número de vectores en relación con los otros modelos.

Sin embargo, se va a probar con valores de parámetros más cercanos al modelo anterior, costo = 800, 850, 900,1000, 1200; 3 grados y escala -200, -150, -100, -90, -50. El mejor modelo obtenido es con costo 120, 3 grados, escala de 70 y 326 vectores.

***Resultados del modelo:***

|<a name="_hlk21477317"></a>Conjunto de Datos|Precisión|Error|Área ROC|
| :-: | :-: | :-: | :-: |
|Entrenamiento|95\.85%|4\.14 %|0\.9928|
|Validación|92\.31%|7\.69 %|0\.8993|
|Pruebas|82\.05%|17\.94%|0\.8724|

*Tabla 27. Evaluación del modelo Polinomial 220 datos cambiando parámetros*

Al validar los resultados generados por el modelo con la nueva aproximación de parámetros vemos que no se logra encontrar un mejor modelo, sino que este tiende a sobre ajustarse y empeora los resultados tanto en entrenamiento, validación y prueba.
#### *Mejor Modelo Polinomial*
Luego de la sintonización del parámetro de costo, grados y escala no se logró encontrar una mejora al primer modelo generado por el kernel polinomial por lo que se presenta este como el mejor.

|<a name="_hlk21477333"></a>Conjunto de Datos|Precisión|Error|Área ROC|
| :-: | :-: | :-: | :-: |
|Entrenamiento|96\.37 %|3\.62 %|0\.9859|
|Validación|84\.21%|10\.76 %|0\.8409|
|Pruebas|83\.33%|16\.67%|0\.8683|

*Tabla 28. Evaluación del mejor modelo polinomial 220 datos*

A continuación, detalle los valores de desempeño en pruebas:

**Matriz de Confusión:**

<table><tr><th colspan="1" rowspan="2" valign="top"><p></p><p>Predicción</p></th><th colspan="2" valign="top">Real - Pruebas</th></tr>
<tr><td colspan="1" valign="top"><b>0</b></td><td colspan="1" valign="top"><b>1</b></td></tr>
<tr><td colspan="1" valign="top">0</td><td colspan="1" valign="top">55</td><td colspan="1" valign="top">1</td></tr>
<tr><td colspan="1" valign="top">1</td><td colspan="1" valign="top">12</td><td colspan="1" valign="top">10</td></tr>
</table>

*Tabla 29.* Matriz de Confusión modelo polinomial con 220 datos

El modelo predice el 90,09% de los casos positivos y una especificidad del 82.08%.

![](048.png)

*Figura 26. Curva ROC del modelo polinomial con 220 datos*

### Modelo Polinomial 1.200

Se genera el modelo lineal con una configuración del valor de costo de 0.005 a 1000, 2 – 3 - 4 grados de libertad, escala de -100 a 100 y con validación cruzada se determina el mejor valor para el parámetro.

`  `*svm\_pol = tune (svm, MANIPULATOR ~., data = datos\_modelo. train, kernel = "polynomial", iter.max=10000000,*

*ranges = list (cost=c (0.005, 0.009, 0.01, 0.05, 0.1, 0.5, 1, 2, 5, 10, 50, 100, 1000), degree = c (2, 3, 4), scale=c (-100, -10, -1, 1, 10, 100)))*

Este proceso nos entrega como mejor modelo el que responde a los parámetros de costo=100, 3 grado, escala 100 y 217 vectores dentro de un conjunto de datos de 1236 observaciones.

***Resultados del modelo:***

|Conjunto de Datos|Precisión|Error|Área ROC|
| :-: | :-: | :-: | :-: |
|Entrenamiento|97\.73 %|2\.26 %|0\.9959|
|Validación|94\.5%|5\.50 %|0\.9368|
|Pruebas|87\.06%|12\.93%|0\.87|

*Tabla 30. Evaluación del modelo Polinomial 1200 datos*

El modelo polinomial, parece generar unos muy buenos resultados que son mejores al modelo lineal pero no alcanzan a igualar el modelo radial, sin embargo, tiene menos menores que el radial por lo que también se considera un buen modelo predictor.

Por lo que, se va a probar con valores de parámetros más cercanos al modelo anterior, costo = 80, 85, 90, 95, 100, 105,110,120, 3 grados y escala 70, 80, 90, 100, 120, 130, 200. El mejor modelo obtenido es con costo 120, 3 grados, escala de 70 y 326 vectores.

***Resultados del modelo:***

|Conjunto de Datos|Precisión|Error|Área ROC|
| :-: | :-: | :-: | :-: |
|Entrenamiento|94\.93 %|5\.07 %|0\.9893|
|Validación|92\.23%|7\.76 %|0\.9356|
|Pruebas|83\.56%|16\.44%|0\.9628|

*Tabla 31. Evaluación del modelo Polinomial 1200 datos cambio valores*

Al validar los resultados generados por el modelo con la nueva aproximación de parámetros vemos que no se logra encontrar un mejor modelo, sino que este tiende a sobre ajustarse y empeora los resultados tanto en entrenamiento, validación y prueba.
#### *Mejor Modelo Polinomial*
Luego de la sintonización del parámetro de costo, grados y escala no se logró encontrar una mejora al primer modelo generado por el método lineal por lo que se presenta este como el mejor.

|<a name="_hlk21477351"></a>Conjunto de Datos|Precisión|Error|Área ROC|
| :-: | :-: | :-: | :-: |
|Entrenamiento|97\.73 %|2\.26 %|0\.9959|
|Validación|94\.5%|5\.50 %|0\.9368|
|Pruebas|87\.06%|12\.93%|0\.87|

*Tabla 33. Evaluación del mejor modelo Polinomial 1200 datos*

A continuación, detalle los valores de desempeño en pruebas:

**Matriz de Confusión:**

<table><tr><th colspan="1" rowspan="2" valign="top"><p></p><p>Predicción</p></th><th colspan="2" valign="top">Real - Pruebas</th></tr>
<tr><td colspan="1" valign="top"><b>0</b></td><td colspan="1" valign="top"><b>1</b></td></tr>
<tr><td colspan="1" valign="top">0</td><td colspan="1" valign="top">312</td><td colspan="1" valign="top">0</td></tr>
<tr><td colspan="1" valign="top">1</td><td colspan="1" valign="top">48</td><td colspan="1" valign="top">11</td></tr>
</table>

*Tabla 34. Matriz de confusión modelo Polinomial 1200 datos*

El modelo predice el 100% de los casos positivos y una especificidad del 86.66%

![](049.png)

*Figura 27. Curva ROC del modelo polinomial con 1200 datos*

### Selección del modelo final
A continuación, los resultados del mejor modelo obtenido para cada tipo de Kernel en los datos de pruebas para el conjunto de 220 observaciones.

|Modelo|Precisión|Error|Especificidad|Área ROC|
| :-: | :-: | :-: | :-: | :-: |
|Lineal|80\.59%|19\.40%|80\.59%|0\.9318|
|Radial|79\.49%|20\.5 %|83\.58%|0\.8344|
|Polinómico|83\.33%|16\.67%|82\.08%|0\.8683|

*Tabla 35. Comparación en los modelos a 220 datos*
###
A continuación, los resultados del mejor modelo obtenido para cada tipo de Kernel en los datos de pruebas para el conjunto de 1200 observaciones.

|Modelo|Precisión|Error|Especificidad|Área ROC|
| :-: | :-: | :-: | :-: | :-: |
|Lineal|80\.59%|19\.40%|80\.27%|0\.9318|
|Radial|100 %|0 %|100%|1|
|Polinómico|87\.06%|12\.93%|86\.66%|0\.87|

` `*Tabla 36. Comparación en los modelos a 1200 datos*


**Análisis de los resultados:** En el modelo realizado con 220 datos el mejor modelo a implementar fue el modelo lineal el cual tiene una presión de los resultados del 88.08 y con la más alta precisión en la curva ROC, sin embargo, cuando se realiza el modelo con la base completa (1200 datos) el mejor modelo parece ser el modelo polinomial el cual tiene una precisión del 87.06% debido a que baja la precisión del modelo lineal y el modelo polinomial aumenta.

Tener en cuenta que para la elección del mejor modelo se descarta el uso del modelo radial debido a que cuando se utiliza la base de datos con 220 datos tiene los peores resultados en precisión y error, adicionalmente en el modelo de 1200 datos se tiene la sospecha de que el modelo se encuentra sobre ajustado al ser un modelo “Perfecto”

**Selección del mejor modelo:** Para seleccionar el modelo a recomendar a la empresa MCA tecnology se deben tener en cuenta aspectos como: facilidad de la implementación, resultados obtenidos, tiempos de demora al correr el modelo entre otros, con los resultados obtenidos en el presente análisis se seleccionaría el modelo lineal con la muestra de (220 casos incluyendo 39 manipuladores)**  

Para realizar la evaluación de los resultados obtenidos en comparación con el modelo Beneish se realiza la aplicación del modelo en los datos segmentados; para realizar la implementación del modelo Beneish se debe aplicar la siguiente formula

M-score=-4.84 + 0.92\*DSRI + 0.528\*GMI + 0.404\*AQI + 0.892\*SGI + 0.115\*DEPI - 0.172\*SGAI + 4.679\*ACCR - 0.327\*LEVI 

En donde si el M- score > -2.22 existe la probabilidad de manipulación, ahora se realiza la comparación con los datos originales, el cual da como resultado: 

![](050.png)

*Figura 29. Modelo de* Beneish aplicado a los datos originales


En donde 0 es < =-2.22 y 1 es > -2,.22

Datos No manipulados: 829

Datos manipulados: 410

Como se puede observar con los datos originales la precisión del modelo esta en 66.9% lo cual esta muy por debajo de los resultados de los modelo obtenidos tanto como los modelos 1200 o 220. 

## Informe final
### Conclusiones

- Al obtener 2 modelos diferentes con resultados superiores lo esperado al aplicar el “modelo Beneish” se puede concluir que, aunque el modelo funciono en empresas estadounidenses al aplicarlo sobre las empresas indias el modelo no tiene la exactitud esperada y por lo tanto se puede mejorar por medio de uso de técnicas de clasificación teniendo en cuenta que, aunque la mejora parece significativa, el modelo Beneish es mucho más fácil de implementar.
- el “modelo Beneish” se basa en una relación lineal de las variables afectadas, dado que el modelo obtenido con la base de datos completa da con una mejor precisión un modelo polinomial se concluye que para las empresas indias la relación de las variables esta no relacionada de forma lineal.
- Se debe tener precaución al implementar el modelo de clasificación sin realizar un balaceo de la base de datos, debido a que se pueden presentar datos de precisión muy alto debido a que es bajo el porcentaje de las empresas que realizan manipulación de sus estados financieros.  

### Estrategias futuras

Para fortalecer el modelo actual desarrollado se puede complementar el trabajo realizado por medio de las siguientes actividades: 

- Analizar los motivos por los cuales se obtuvo modelo radial de precisión 100% cuando se aplicaron los 1200 datos que lo puede hacer un modelo inestable.
- Se puede aplicar sobre los mismos datos modelos de clasificación diferentes SVN como lo pueden ser KNN, Arboles de decisión, regresión entre otros y comparar los resultados a fin de mejorar la precisión del modelo
- Se pueden analizar a profundidad el desbalanceo de la base de datos en donde se pueda llegar a predecir entre los rangos de valores que el modelo se comporta de mejor manera aplicando las técnicas para balancear las bases de datos. 

### Preguntas

- **¿Cree Usted que el modelo Beneish desarrollado en 1999 será aún relevante para los datos de India?**

Desde nuestro punto de vista y al realizar la aplicación del modelo Beneish en los datos se puede llegar a evidenciar que el modelo no tienen la precisión de predicción esperada debido a que la obtenida fue de un 66.9% en comparación con el 88.08 % para el modelo lineal en  220 datos, el 100% del modelo radial con1236 datos o el 87.06% del modelo polinomial en 1236 datos, por lo tanto no se consideraría relevante el uso de este modelo en los datos de la India. Debemos tener presente que el caso desarrollado en estados unidos sobre este mismo problema no se estaba utilizando estrategias de modelado de datos sino estimaciones estadísticas por las cuales se llegaba a ver probabilidades de ser manipulador dependiendo de diferentes combinaciones de características, pero no se tenía un dictamen final sobre quienes eran o no manipuladores.

- **El número de manipuladores es usualmente mucho menor que el de no-manipuladores.  ¿Qué tipo de problemas de modelamiento puede uno esperar cuando los casos en una clase son mucho menores que la otra clase, en clasificación binaria?  ¿Cómo se pueden atacar estos problemas?**

El problema con las bases de datos desbalanceadas es que el modelador puede asumir por votación que siempre se va a inclinar hacia la clase donde hay mayoría de datos, para este caso puntual el 97% de los datos pertenecen a la clase no manipulada, por lo tanto si el modelo asume que ninguna empresa manipula sus estados financieros se puede decir que el modelo tiene un 97% de precisión lo cual aunque puede ser cierto el modelo no está prediciendo las empresa que manipulan sus datos. 

Una de las formas de corregir esto es realizando el balanceo de las bases de datos, esto se puede realizar por diversas técnicas tales como Under-Sampling u Over Sampling las cuales consisten en eliminar datos de la mayor categoría con el fin de reducir la brecha entre las categorías o repetir los datos de las categorías que tiene menos datos hasta equilibrar con la categoría mayor. Otras formas no utilizadas en el presente análisis en el lograr dar un peso a la clasificación de las variables con esto se logra que se le además prioridad a la clasificación de la categoría menor.

- **Comente sobre el modelo desarrollado; cómo se puede medir la exactitud del modelo?**

Para medir la exactitud de los modelos obtenidos se utilizan 2 técnicas de comparación uno es a partir de la matriz de confusión se puede determinar por medio de la siguiente ecuación: 

Acurrcy= Verdaderos positivos+Verdaderos NegativosTotal\*100

La cual nos indica el porcentaje de acierto de nuestro modelo evaluado. 

La otra técnica utilizada para la medición de la exactitud del modelo es por medio del análisis de la curva ROC la cual por medio del análisis del área bajo la curva nos indicia la exactitud del modelo obtenido. 

- **¿Cuál de los 2 modelos desarrollados debería utilizar MCA Technologies?** 

Desde nuestro punto de vista MCA Tecnhology Solutions debería utilizar el modelo de 220 casos incluyendo 39 manipuladores, cuando no se tiene un balanceo adicional de datos. Ya que al utilizar manos caso de no manipulables estamos permitiendo al modelo estudiar conocer en mejor proporción los datos manipulados. Sin embargo, para los modelos realizados con un balanceo automático de 70/30 con todos los datos se evidencio que esto mejora la exactitud de los modelos por lo que se recomienda utilizar un modelo radial con todos los datos. 

- **¿Cuál debería ser la estrategia adoptada por MCA Tecnhology Solutions para implementar este modelo?**

La estrategia que debería utilizar la empresa MCA Tecnhology Solutions es la empezar automatizar la extracción y preparación de la base de datos a fin de reducir los tiempos de ejecución del modelo, adicionalmente se debe probar el modelo con información reciente a fin de ir complementado la base de datos actual y darle una mejora continua a modelo.

También se recomienda ir reentrenando el modelo contantemente con el fin de evitar que se pierda su efectividad.


# Referencias
NASER, K. (1993). Creative Financial Accounting: Its Nature and Use. Londres: Prentice Hall.

Santos Cid, Carlos Manuel. (2016). La contabilidad creativa, el directivo y la ética organizacional. *Retos de la Dirección*, *10*(2), 46-77. Recuperado en 25 de septiembre de 2019, de <http://scielo.sld.cu/scielo.php?script=sci_arttext&pid=S2306-91552016000200004&lng=es&tlng=es>

López, M.R. (2016). Cómo detectar el fraude contable y la contabilidad creativa.




